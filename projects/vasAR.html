<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Carmine Elvezio</title>
        <meta name="description" content="" />
        <meta name="keywords" content="" />
        <meta name="author" content="SRBThemes" />

        <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
        
        <link rel="shortcut icon" href="../images/favicon.ico">

        <!--Bootstrap Css-->
        <link rel="stylesheet" type="text/css" href="../css/bootstrap.min.css" />

        <!-- Materialdesign icons Css -->
        <link href="../css/materialdesignicons.min.css" rel="stylesheet">

        <!-- Mobirise icons Css -->
        <link href="../css/mobiriseicons.css" rel="stylesheet"> 

        <!-- Magnific-popup -->
        <link rel="stylesheet" href="../css/magnific-popup.css">

        <!-- Animate Css -->
        <link rel="stylesheet" href="../css/animate.min.css">

        <!-- OWL SLIDER -->
        <link rel="stylesheet" href="../css/owl.carousel.css" />
        <link rel="stylesheet" href="../css/owl.theme.css" />
        <link rel="stylesheet" href="../css/owl.transitions.css" />

        <!-- Custom style Css -->
        <link href="../css/style.css" rel="stylesheet">
        <link href="../css/color/default.css" rel="stylesheet" id="option-color">
    </head>

    <body>



        <!-- Start Navbar -->
    	<nav class="navbar navbar-expand-lg fixed-top custom-nav sticky">
            <div class="container">

                <a class="navbar-brand pt-0 logo" href="../index.html">
                    <img src="../images/logo.png" alt="" class="img-fluid logo-light">
                    <img src="../images/logo-dark.png" alt="" class="img-fluid logo-dark">
                </a>

                <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="mdi mdi-menu"></span>
                </button>

                <div class="collapse navbar-collapse" id="navbarCollapse">
                    <ul class="navbar-nav ml-auto">
<!--
                        <li class="nav-item active">
                            <a class="nav-link" href="#home">Home</a>
                        </li>
-->
                        <li class="nav-item">
                            <a class="nav-link" href="#about">About</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#media">Media</a>
                        </li>
                        <li class="nav-item">
                            <a class="nav-link" href="#publications">Publications</a>
                        </li>

                    </ul>
                </div>
            </div>
        </nav>
        <!-- End Navbar -->
        
        <!-- START HOME -->
        <section class="section header-bg-img h-50vh" id="home" style="background-image:url(../images/proj_images/VasAR/image_UI_1.png)">
            <div class="bg-overlay" style="background-color:rgba(38, 40, 43, 0.78)"></div>
            <div class="header-table">
                <div class="header-table-center">
                    <div class="container">
                        <div class="row justify-content-center">
                            <div class="col-lg-12">
                                <div class="text-center header-content mx-auto">
                                    <h4 class="text-white first-title mb-4">VasAR</h4>
                                    <h1 class="header-name text-white text-capitalize mb-0">AR-guided Non-invasive Medical Procedures</h1>                            
                                </div>
                            </div>
                        </div>
                        <br>
                        <div class="row align-items-center">
                            <div class="col-lg-12">
                                <div class="text-center">
                                    <div class="mt-3">
                                        <h5><span class="font-weight-bold">
                                            <a href="https://www.linkedin.com/in/shirin-sadri-54838698/">Shirin Sadri</a>,
                                            <a href="https://www.linkedin.com/in/gabrielle-loeb-05179646/">Gabrielle Loeb</a>,
                                            Carmine Elvezio, 
                                            <a href="https://www.linkedin.com/in/alongrinshpoon">Alon Grinshpoon</a>,
                                            <a href="http://www.cs.columbia.edu/~feiner/" class="text-custom font-weight-bold">Steve Feiner</a>,
                                                et al.
                                            </span></h5>                            
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>  
        </section>
        <!-- END HOME -->

        <!-- START ABOUT -->
        <section class="section" id="about">
            <div class="container">
                <div class="row align-items-center">
                    <div class="col-lg-6">
                        <div class="mt-3">
                            <h2><span class="font-weight-bold">Providing AR-based guidance to physicans performing time-critical medical procedures.</span></h2>
                            <h4 class="mt-4"><span class="text-custom font-weight-bold">2016-2021</span></h4>
                            <p class="text-muted mt-4">Augmented reality (AR) can improve a number of medical procedures by providing 3D visualization of patient anatomy, with potential to reduce contrast and procedure time. We present a novel AR guidance system that displays virtual, patient-specific 3D anatomic models and assess intraprocedural impact during TAVR with CEP in six patients.</p>
                            <br>
                            <p>Presented at <a href="https://ieeexplore.ieee.org/abstract/document/8943734">IEEE ISMAR 2019</a>, the <a href="https://medium.com/@nycmedialab/nyc-media-lab-awards-25-000-in-prizes-for-emerging-media-technology-research-projects-prototypes-d144f810bda3">NYC Media Lab Summit 2018</a> and <a href="https://dl.acm.org/doi/abs/10.1145/3214907.3236462">ACM SIGGRAPH 2018.</a></p>
                        </div>
                    </div>
                    <div class="col-lg-6">
                        <div class="mt-3">
                            <div class="video-responsive">
                                <iframe width="560" height="315" src="https://www.youtube.com/embed/eK42UEbMQvw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- END ABOUT -->

        <!--START WORK -->   
        <section class="section bg-light" id="media">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="text">
                            <h2><span class="font-weight-bold">Media</span></h2>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row mt-4 work-filter">
                    <div class="col-lg-4 work_item">
                        <a href="../images/proj_images/VasAR/image_EndovascularSurgery.jpg" class="img-zoom">
                            <div class="work_box">
                                <div class="work_img">
                                    <img src="../images/proj_images/VasAR/image_EndovascularSurgery.jpg" class="img-fluid mx-auto d-block rounded" alt="work-img">
                                </div>
                                <div class="work_detail text-center">
                                    <h4 class="mb-0">Physician performing interventional medical procedure without AR guidance system.</h4>
                                </div>
                            </div>
                        </a>
                    </div>

                    <div class="col-lg-4 work_item">
                        <a href="../images/proj_images/VasAR/image_UI_1.png" class="img-zoom">
                            <div class="work_box">
                                <div class="work_img">
                                    <img width="800" height="533" src="../images/proj_images/VasAR/image_UI_1.png" class="img-fluid mx-auto d-block rounded" style="object-fit:fill" alt="work-img">
                                </div>
                                <div class="work_detail text-center">
                                    <h4 class="mb-0">AR guidance system presenting patient-specific tissue visualization in 3D.</h4>
                                </div>
                            </div>
                        </a>
                    </div>

                    <div class="col-lg-4 work_item">
                        <a href="../images/proj_images/VasAR/VasAR_Teaser.png" class="img-zoom">
                            <div class="work_box">
                                <div class="work_img">
                                    <img src="../images/proj_images/VasAR/VasAR_Teaser.png" class="img-fluid mx-auto d-block rounded" alt="work-img">
                                </div>
                                <div class="work_detail text-center">
                                    <h4 class="mb-0">Physicians wear HoloLens, which provides AR view of patient anatomy wherever needed.</h4>
                                </div>
                            </div>
                        </a>
                    </div>

                    <div class="col-lg-4 work_item">
                        <a href="../images/proj_images/VasAR/TeaserV2_2.png" class="img-zoom">
                            <div class="work_box">
                                <div class="work_img">
                                    <img src="../images/proj_images/VasAR/TeaserV2_2.png" class="img-fluid mx-auto d-block rounded" alt="work-img">
                                </div>
                                <div class="work_detail text-center">
                                    <h4 class="mb-0">Physicians can view, manipulate, and explore patient anatomy completely hands-free.</h4>
                                </div>
                            </div>
                        </a>
                    </div>
                </div>
            </div>
        </section>
        <!--END WORK -->
        
        <!-- START PUBLICATIONS -->
		<section class="section" id="publications">
            <div class="container">   
                <div class="row">
                    <div class="col-lg-12">
                        <div class="text">
                            <h2><span class="font-weight-bold">Publications</span></h2>
                        </div>
                    </div>
                </div> 
                
                <br>
				
				<div class="row" id="paper_seq23">
					<div class="col-lg-12">
						<h4>Systems and methods for augmented reality guidance</h4>
					</div>
					<div class="col-md-12 text-muted">
						 Steven Feiner, Gabrielle Loeb, Alon Grinshpoon, Shirin Sadri, Carmine Elvezio
					</div>
				  <div class="col-md-12 text-muted">
						 US Patent #16796645
					</div>
					  <div class="col-md-12">
					  [<a target="_blank" href="https://patents.google.com/patent/US20200188028A1/en">US Patent</a>]
                      <input type="checkbox" id="my_checkbox23" style="display:none;">
                          [<label for="my_checkbox23">Abstract</label>]
                                <div id="hidden">Certain embodiments include a method for assisting a clinician in performing a medical procedure on a patient using augmented reality guidance. The method can include obtaining a three-dimensional model of an anatomic part of the patient. The method can also include aligning the three-dimensional model with data to form augmented reality guidance for the medical procedure. In addition, the method can include presenting the augmented reality guidance to the clinician during the medical procedure using an augmented reality three-dimensional display.</div>
					</div>
				</div>
				
				<br>
                
                <div class="row" id="paper_seq21">
					<div class="col-lg-12">
						<h4>Manipulating 3D Anatomic Models in Augmented Reality: Comparing a Hands-Free Approach and a Manual Approach</h4>
					</div>
					<div class="col-md-12 text-muted">
						 Shirin Sadri, Shalva Kohen, Carmine Elvezio, Shawn Sun, Alon Grinshpoon, Gabrielle Loeb, Naomi Basu, Steven Feiner
					</div>
				  <div class="col-md-12 text-muted">
						 IEEE ISMAR 2019
					</div>
					  <div class="col-md-12">
					  [<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/8943734">IEEE Xplore</a>]
                      <input type="checkbox" id="my_checkbox21" style="display:none;">
                          [<label for="my_checkbox21">Abstract</label>]
                                <div id="hidden">Many AR and VR task domains involve manipulating virtual objects; for example, to perform 3D geometric transformations. These operations are typically accomplished with tracked hands or hand-held controllers. However, there are some activities in which the user's hands are already busy with another task, requiring the user to temporarily stop what they are doing to perform the second task, while also taking time to disengage and reengage with the original task (e.g., putting down and picking up tools). To avoid the need to overload the user's hands this way in an AR system for guiding a physician performing a surgical procedure, we developed a hands-free approach to performing 3D transformations on patient-specific virtual organ models. Our approach uses small head motions to accomplish first-order and zero-order control, in conjunction with voice commands to establish the type of transformation. To show the effectiveness of this approach for translating, scaling, and rotating 3D virtual models, we conducted a within-subject study comparing the hands-free approach with one based on conventional manual techniques, both running on a Microsoft HoloLens and using the same voice commands to specify transformation type. Independent of any additional time to transition between tasks, users were significantly faster overall using the hands-free approach, significantly faster for hands-free translation and scaling, and faster (although not significantly) for hands-free rotation.</div>      
					</div>
				</div>				
				
				<br> 
                
                <div class="row" id="paper_seq18">
					<div class="col-lg-12">
						<h4>Augmented reality guidance for cerebral embolic protection (CEP) with the sentinel device during transcatheter aortic valve replacement (TAVR): First-in-human study</h4>
					</div>
					<div class="col-md-12 text-muted">
						 Shirin Sadri, Gabrielle Loeb, Alon Grinshpoon, Carmine Elvezio, Poonam Velagapudi, Vivian G Ng, Omar Khalique, Jeffrey W Moses, Robert J Sommer, Amisha J Patel, Isaac George, Rebecca T Hahn, Martin B Leon, Ajay J Kirtane, Tamim M Nazif, Susheel K Kodali, Steven K Feiner, Torsten P Vahl
					</div>
				  <div class="col-md-12 text-muted">
						 Circulation 2019
					</div>
					  <div class="col-md-12">
					  [<a target="_blank" href="https://www.ahajournals.org/doi/abs/10.1161/circ.138.suppl_1.12019">AHA Circulation</a>]
                      <input type="checkbox" id="my_checkbox18" style="display:none;">
                          [<label for="my_checkbox18">Abstract</label>]
                                <div id="hidden">Augmented reality (AR) can improve transcatheter interventions by providing 3D visualization of patient anatomy, with potential to reduce contrast and procedure time. We present a novel AR guidance system that displays virtual, patient-specific 3D anatomic models and assess intraprocedural impact during TAVR with CEP in six patients.</div>
					</div>
				</div>
				
				<br>
                
                <div class="row" id="paper_seq14">
					<div class="col-lg-12">
						<h4>Hands-free augmented reality for vascular interventions</h4>
					</div>
					<div class="col-md-12 text-muted">
						 Alon Grinshpoon, Shirin Sadri, Gabrielle J Loeb, Carmine Elvezio, Samantha Siu, Steven K Feiner
					</div>
				  <div class="col-md-12 text-muted">
						 ACM SIGGRAPH 2018
					</div>
					  <div class="col-md-12">
					  [<a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3214907.3236462">ACM DL</a>]
                      <input type="checkbox" id="my_checkbox14" style="display:none;">
                          [<label for="my_checkbox14">Abstract</label>]
                                <div id="hidden">During a vascular intervention (a type of minimally invasive surgical procedure), physicians maneuver catheters and wires through a patient's blood vessels to reach a desired location in the body. Since the relevant anatomy is typically not directly visible in these procedures, virtual reality and augmented reality systems have been developed to assist in 3D navigation. Because both of a physician's hands may already be occupied, we developed an augmented reality system supporting hands-free interaction techniques that use voice and head tracking to enable the physician to interact with 3D virtual content on a head-worn display while leaving both hands available intraoperatively. We demonstrate how a virtual 3D anatomical model can be rotated and scaled using small head rotations through first-order (rate) control, and can be rigidly coupled to the head for combined translation and rotation through zero-order control. This enables easy manipulation of a model while it stays close to the center of the physician's field of view.</div>
					</div>
				</div>		
				
				<br>
                
                <div class="row" id="paper_seq10">
					<div class="col-lg-12">
						<h4>3: 54 PM Abstract No. 29 Augmented reality guidance for cerebral angiography</h4>
					</div>
					<div class="col-md-12 text-muted">
						 G Loeb, S Sadri, A Grinshpoon, J Carroll, C Cooper, C Elvezio, S Mutasa, G Mandigo, S Lavine, J Weintraub, A Einstein, S Feiner, P Meyers
					</div>
				  <div class="col-md-12 text-muted">
						 Journal of Vascular and Interventional Radiology 2018
					</div>
					  <div class="col-md-12">
					  [<a target="_blank" href="https://www.researchgate.net/publication/324142809_354_PM_Abstract_No_29_Augmented_reality_guidance_for_cerebral_angiography">Research Gate</a>]
                      <input type="checkbox" id="my_checkbox10" style="display:none;">
                          [<label for="my_checkbox10">Abstract</label>]
                                <div id="hidden">Augmented reality (AR) holds great potential for IR byintegrating virtual 3D anatomic models into the real world.1In thispilot study, we developed an AR guidance system for cerebralangiography, evaluated its impact on radiation, contrast, and ﬂuo-roscopy time, and assessed physician response.</div>
					</div>
				</div>				
				
				<br>
                
                <div class="row" id="paper_seq9">
					<div class="col-lg-12">
						<h4>Hands-free interaction for augmented reality in vascular interventions</h4>
					</div>
					<div class="col-md-12 text-muted">
						 Alon Grinshpoon, Shirin Sadri, Gabrielle J Loeb, Carmine Elvezio, Steven K Feiner
					</div>
				  <div class="col-md-12 text-muted">
						 IEEE VR 2018
					</div>
					  <div class="col-md-12">
					  [<a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/8446259/">IEEE Xplore</a>]
                      <input type="checkbox" id="my_checkbox9" style="display:none;">
                          [<label for="my_checkbox9">Abstract</label>]
                                <div id="hidden">Vascular interventions are minimally invasive surgical procedures in which a physician navigates a catheter through a patient's vasculature to a desired destination in the patient's body. Since perception of relevant patient anatomy is limited in procedures of this sort, virtual reality and augmented reality systems have been developed to assist in 3D navigation. These systems often require user interaction, yet both of the physician's hands may already be busy performing the procedure. To address this need, we demonstrate hands-free interaction techniques that use voice and head tracking to allow the physician to interact with 3D virtual content on a head-worn display while making both hands available intraoperatively. Our approach supports rotation and scaling of 3D anatomical models that appear to reside in the surrounding environment through small head rotations using first-order control, and rigid body transformation of those models using zero-order control. This allows the physician to easily manipulate a model while it stays close to the center of their field of view.</div>
					</div>
				</div>					
				
				<br>
                
                <br>
				
            </div>
        </section>
		<!-- END PUBLICATIONS -->

        <!--START FOOTER-->
        <footer class="footer bg-light">
            <div class="container">
                <div class="row justify-content-center text-center">
                    <div class="col-md-12">
                        <div class="text-center text-white footer-alt">
                            <ul class="list-unstyled list-inline mb-3">
									<li class="list-inline-item"><a href="https://www.linkedin.com/in/carmine-elvezio-23711a14"><i class="mdi mdi-linkedin text-muted"></i></a></li>
                                    <li class="list-inline-item"><a href="https://github.com/ce2236"><i class="mdi mdi-github-circle text-muted"></i></a></li>
								  	<li class="list-inline-item"><a href="https://scholar.google.com/citations?user=kp4b3qQAAAAJ"><i class="ai ai-google-scholar-square ai-1x text-muted"></i></a></li>
									<li class="list-inline-item"><a href="https://www.researchgate.net/profile/Carmine_Elvezio"><i class="ai ai-researchgate ai text-muted"></i></a></li>
									<li class="list-inline-item"><a href="https://www.semanticscholar.org/author/Carmine-Elvezio/2030511"><i class="ai ai-semantic-scholar-square ai text-muted"></i></a></li>
									<li class="list-inline-item"><a href="mailto:carmine@cs.columbia.edu"><i class="mdi mdi-email text-muted"></i></a></li>
                            </ul>
                            <p class="text-muted mb-0"> 2021 &copy; Carmine Elvezio. Design by SRBThemes.</p>
                        </div>
                    </div>
                </div>
            </div>
        </footer>
        <!--END FOOTER-->

        

        <!-- Back To Top -->    
        <a href="#" class="back_top"> <i class="mdi mdi-chevron-up"> </i> </a>
      
        <!-- JAVASCRIPTS -->
        <script src="../js/jquery.min.js"></script>
        <script src="../js/popper.min.js"></script>
        <script src="../js/bootstrap.min.js"></script>
        <!--EASING JS-->
        <script src="../js/jquery.easing.min.js"></script>
        <script src="../js/scrollspy.min.js"></script>
        <!--PORTFOLIO FILTER JS-->
        <script src="../js/isotope.js"></script>
        <!-- Magnific Popup Js -->
        <script src="../js/jquery.magnific-popup.min.js"></script>
        <!-- TYPED -->
        <script src="../js/typed.js"></script>
        <!-- OWL CAROUSEL -->
        <script src="../js/owl.carousel.min.js"></script>
        <!-- CONTACT JS -->
        <script src="../js/contact.js"></script>
        <!--CUSTOM JS-->
        <script src="../js/custom.js"></script>
    </body>
</html>
